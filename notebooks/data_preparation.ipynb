{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T16:47:27.976640Z",
     "start_time": "2017-09-06T16:47:27.960781Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import subprocess\n",
    "from collections import namedtuple, defaultdict\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "import helpers\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T17:05:04.078078Z",
     "start_time": "2017-09-06T17:04:34.303643Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPLIT_ID = 1\n",
    "\n",
    "DATASET_PATH = '/data/data/ucf101/'\n",
    "DATA_PATH = os.path.join(DATASET_PATH, 'UCF-101')\n",
    "\n",
    "PREPROCESSED_PATH = '/data/data/ucf101_preprocessed'\n",
    "PREPROCESSED_SPLIT_PATH = os.path.join(PREPROCESSED_PATH, 'split_{0:02d}'.format(SPLIT_ID))\n",
    "\n",
    "FPS = 5\n",
    "WIDTH = 320\n",
    "HEIGHT = 240\n",
    "\n",
    "SKIP_EXIST = True\n",
    "\n",
    "FNULL = open(os.devnull, 'w')\n",
    "\n",
    "if not SKIP_EXIST:\n",
    "    shutil.rmtree(PREPROCESSED_SPLIT_PATH, ignore_errors=True)\n",
    "    \n",
    "helpers.ensure_path_exists(PREPROCESSED_SPLIT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T17:05:04.095660Z",
     "start_time": "2017-09-06T17:05:04.078905Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Video(namedtuple('VideoPath', ['class_', 'name', 'extension'])):\n",
    "    @classmethod\n",
    "    def parse_split_line(cls, line):\n",
    "        path, extension = os.path.splitext(line.strip())\n",
    "        class_, name = os.path.split(path)\n",
    "        \n",
    "        return cls(class_=class_, name=name, extension=extension)\n",
    "    \n",
    "    @property\n",
    "    def path(self):\n",
    "        return '{0.class_}/{0.name}{0.extension}'.format(self)\n",
    "    \n",
    "    @property\n",
    "    def path_no_ext(self):\n",
    "        return '{0.class_}/{0.name}'.format(self)   \n",
    "    \n",
    "    \n",
    "def get_split_videos(train_or_test):\n",
    "    assert train_or_test in {'train', 'test'}\n",
    "    \n",
    "    path = os.path.join(DATASET_PATH, 'ucfTrainTestlist', '{0}list{1:02d}.txt'.format(train_or_test, SPLIT_ID))\n",
    "\n",
    "    with open(path) as f:\n",
    "        return [Video.parse_split_line(l.strip().split()[0]) for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для разбиения sp1 генерим RGB с помощью FFMPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T17:05:04.144486Z",
     "start_time": "2017-09-06T17:05:04.096622Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_rgb(train_or_test, n_jobs=8):\n",
    "    dst_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test)\n",
    "    rgb_path = os.path.join(dst_path, 'rgb')\n",
    "    \n",
    "    videos = get_split_videos(train_or_test)\n",
    "    \n",
    "    # prepare dirs\n",
    "    classes = {video.class_ for video in videos}\n",
    "    [helpers.ensure_path_exists(os.path.join(rgb_path, class_)) for class_ in classes]\n",
    "    \n",
    "    def prepare_tasks():\n",
    "        for video in videos:\n",
    "            src_video_path = os.path.join(DATA_PATH, video.path)\n",
    "            dst_video_path = os.path.join(rgb_path, video.path_no_ext)\n",
    "        \n",
    "            if SKIP_EXIST and os.path.exists(dst_video_path)\\\n",
    "                and os.path.isdir(dst_video_path) and os.listdir(dst_video_path):\n",
    "                    continue\n",
    "                    \n",
    "            helpers.ensure_path_exists(dst_video_path)\n",
    "            dst_frames_template_path = os.path.join(dst_video_path, '%04d.jpg')\n",
    "            \n",
    "            yield src_video_path, dst_frames_template_path, FPS, WIDTH, HEIGHT\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    def do_work(pool):\n",
    "        with tqdm_notebook(desc='[{}] RGB Generation'.format(train_or_test), total=len(videos)) as pbar:\n",
    "            for is_ok, src_video_path in pool(helpers.extract_rgb_frames, prepare_tasks()):\n",
    "                pbar.update(1)\n",
    "                \n",
    "                if not is_ok:\n",
    "                    errors.append(src_video_path)\n",
    "                    \n",
    "    def dummy_pool(func, tasks):\n",
    "        for task in tasks:\n",
    "            yield func(task)\n",
    "\n",
    "    \n",
    "    if n_jobs > 1:\n",
    "        with multiprocessing.Pool(n_jobs) as pool:\n",
    "            do_work(pool.imap_unordered)\n",
    "    else:\n",
    "        do_work(dummy_pool)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T17:12:04.161775Z",
     "start_time": "2017-09-06T17:05:04.146080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8745208fab4349b2995a4880534ffc55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c9f73190604c3da9fde0c52cc83a86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_errors = generate_rgb('train', 4)\n",
    "test_errors = generate_rgb('test', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Будем генерить оптический поток с помощью flownet 2.0 из контейнера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T17:12:04.238731Z",
     "start_time": "2017-09-06T17:12:04.163116Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_flow_tasks(train_or_test):\n",
    "    _1st_images, _2nd_images, flow_images = [], [], []\n",
    "    \n",
    "    n_skipped = 0\n",
    "    \n",
    "    rgb_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test, 'rgb')\n",
    "    flow_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test, 'flow')\n",
    "    helpers.ensure_path_exists(flow_path)\n",
    "    \n",
    "    path_prefix_len = len(PREPROCESSED_SPLIT_PATH) + 1\n",
    "    \n",
    "    for class_ in tqdm_notebook(os.listdir(rgb_path), desc='[{}] Flow Task Generation'.format(train_or_test)):\n",
    "        src_class_path = os.path.join(rgb_path, class_)\n",
    "        dst_class_path = os.path.join(flow_path, class_)\n",
    "        helpers.ensure_path_exists(dst_class_path)\n",
    "        \n",
    "        for video_name in os.listdir(src_class_path):\n",
    "            src_video_path = os.path.join(src_class_path, video_name)\n",
    "            dst_video_path = os.path.join(dst_class_path, video_name)\n",
    "            helpers.ensure_path_exists(dst_video_path)            \n",
    "            \n",
    "            frame_names = list(sorted(os.listdir(src_video_path)))\n",
    "            \n",
    "            for _1st_frame, _2nd_frame in zip(frame_names, frame_names[1:]):\n",
    "                _1st_frame_path = os.path.join(src_video_path, _1st_frame)\n",
    "                _2nd_frame_path = os.path.join(src_video_path, _2nd_frame)\n",
    "                \n",
    "                flow_frame_path = os.path.join(dst_video_path, _1st_frame.replace('.jpg', '.flo'))\n",
    "                \n",
    "                if SKIP_EXIST and os.path.exists(flow_frame_path):\n",
    "                    n_skipped += 1\n",
    "                    continue\n",
    "                    \n",
    "                _1st_frame_path = _1st_frame_path[path_prefix_len:]\n",
    "                _2nd_frame_path = _2nd_frame_path[path_prefix_len:]\n",
    "                flow_frame_path = flow_frame_path[path_prefix_len:]\n",
    "                \n",
    "                _1st_images.append(_1st_frame_path)\n",
    "                _2nd_images.append(_2nd_frame_path)\n",
    "                flow_images.append(flow_frame_path)               \n",
    "    \n",
    "    tasks_dir = os.path.join(PREPROCESSED_SPLIT_PATH, 'flow_tasks', train_or_test)\n",
    "    helpers.ensure_path_exists(tasks_dir)\n",
    "    \n",
    "    path_list_name = [\n",
    "        [_1st_images, '1st'],\n",
    "        [_2nd_images, '2nd'],\n",
    "        [flow_images, 'flow']\n",
    "    ]\n",
    "        \n",
    "    for path_list, name in path_list_name:\n",
    "        with open(os.path.join(tasks_dir, '{}.txt'.format(name)), 'w+') as f:\n",
    "            for path in path_list:\n",
    "                f.write(path + '\\n')\n",
    "            f.write(path_list[-1])\n",
    "                \n",
    "    print(train_or_test, 'skipped', n_skipped, 'frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-07T00:18:05.802105Z",
     "start_time": "2017-09-07T00:18:05.612089Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf7a9b86de748af907e35b31a826aa4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test skipped 0 frames\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc685e81aec4407a71bbb9074ce8f50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train skipped 0 frames\n"
     ]
    }
   ],
   "source": [
    "generate_flow_tasks('test')\n",
    "generate_flow_tasks('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# сгенерим .sh для запуска генерации потока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T17:24:29.534031Z",
     "start_time": "2017-09-06T17:24:29.518848Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_sh(train_or_test):\n",
    "    run_file_path = 'run-network.sh'\n",
    "\n",
    "    tasks_dir = os.path.join(PREPROCESSED_SPLIT_PATH, 'flow_tasks', train_or_test)\n",
    "\n",
    "    base_command = 'sh {run_file} -n FlowNet2-s {{img1}} {{img2}} {{flow}}'.format(run_file=run_file_path)\n",
    "п\n",
    "    with open(os.path.join(tasks_dir, 'gen_flow.sh'), 'w+') as f:\n",
    "        img1_list_path = os.path.join('flow_tasks', train_or_test, '1st.txt')\n",
    "        img2_list_path = os.path.join('flow_tasks', train_or_test, '2nd.txt')\n",
    "        flow_list_path = os.path.join('flow_tasks', train_or_test, 'flow.txt')\n",
    "\n",
    "        f.write(base_command.format(img1=img1_list_path, img2=img2_list_path, flow=flow_list_path) + '\\n')\n",
    "            \n",
    "gen_sh('test')\n",
    "gen_sh('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посчитаем mean/std по rgb и потокам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip_img_by_channel(img):\n",
    "    def get_real_max(x):\n",
    "        \"\"\"assume all x are positive\"\"\"\n",
    "        max_diff = np.median(x) * 6\n",
    "        x = np.sort(x)[::-1]\n",
    "\n",
    "        diffs = x[:-1] - x[1:]\n",
    "\n",
    "        max_diff_i = None\n",
    "\n",
    "        for i, diff in enumerate(diffs[:-1]):\n",
    "            if diff >= max_diff:\n",
    "                max_diff_i = i\n",
    "                break\n",
    "\n",
    "        if max_diff_i is None:\n",
    "            return\n",
    "\n",
    "        return x[i + 2]\n",
    "    \n",
    "    img = img.copy()\n",
    "\n",
    "    for channel_i in range(img.shape[2]):\n",
    "        channel = img[:,:,channel_i]\n",
    "        \n",
    "        neg_abs, pos = np.abs(channel[channel < 0].ravel()), channel[channel > 0].ravel()\n",
    "        \n",
    "        if len(neg_abs):\n",
    "            min_val = -(get_real_max(neg_abs) or neg_abs.max())\n",
    "        else:\n",
    "            min_val = channel.min()\n",
    "            \n",
    "        if len(pos):\n",
    "            max_val = get_real_max(pos) or pos.max()\n",
    "        else:\n",
    "            max_val = channel.max()\n",
    "        \n",
    "        img[:,:,channel_i] = np.clip(channel, min_val, max_val)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_train_mean_std(img_type):\n",
    "    def get_file_count(path):\n",
    "        return int(subprocess.getoutput(r'find ' + path + ' -type f | wc -l'))\n",
    "    \n",
    "    def load_flo(path):\n",
    "        img = np.fromfile(path, np.float32, HEIGHT * WIDTH * 2)\n",
    "        img = img.reshape(HEIGHT, WIDTH, 2)\n",
    "        img[0, 0, :] = img.reshape(HEIGHT * WIDTH, 2)[1:].mean(axis=0)\n",
    "        img -= np.min(img, axis=(0, 1))\n",
    "        img = img / np.max(img, axis=(0, 1))\n",
    "        return img\n",
    "    \n",
    "    def load_rgb(path):\n",
    "        img = skimage.io.imread(path)\n",
    "        img = img / 255.\n",
    "        return img\n",
    "    \n",
    "    if img_type == 'rgb':\n",
    "        extension = 'jpg'\n",
    "        load_img_fn = load_rgb\n",
    "        n_channels = 3\n",
    "    elif img_type == 'flow':\n",
    "        extension = 'flo'\n",
    "        load_img_fn = load_flo\n",
    "        n_channels = 2\n",
    "    else:\n",
    "        raise Exception('Invalid type')\n",
    "    \n",
    "    train_path = os.path.join(PREPROCESSED_SPLIT_PATH, 'train', img_type)\n",
    "\n",
    "    file_gen = glob.iglob('{}/**/*.{}'.format(train_path, extension), recursive=True)\n",
    "    file_count = get_file_count(train_path)\n",
    "\n",
    "    mean, std = np.zeros((n_channels,)), np.zeros((n_channels,))\n",
    "    count = 0\n",
    "    \n",
    "    for img_path in tqdm_notebook(file_gen, total=file_count):\n",
    "        img = load_img_fn(img_path)\n",
    "        \n",
    "        count += 1\n",
    "        mean += img.mean(axis=(0, 1))\n",
    "        std += img.std(axis=(0, 1))\n",
    "        \n",
    "    return {\n",
    "        'img_type': img_type,\n",
    "        'mean': mean / count,\n",
    "        'std': std / count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1484a02a3d4d669f3993add45522c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dc74558cb74ed69e7fa9a34dda6137"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rgb_stat = calc_train_mean_std('rgb')\n",
    "flow_stat = calc_train_mean_std('flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_type': 'rgb',\n",
       " 'mean': array([ 0.39674431,  0.38155164,  0.35283176]),\n",
       " 'std': array([ 0.24261944,  0.23637967,  0.23292163])}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_type': 'flow',\n",
       " 'mean': array([ 0.49372829,  0.54430225]),\n",
       " 'std': array([ 0.13754837,  0.14878529])}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Починим потоки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_flows(train_or_test):\n",
    "    def get_file_count(path):\n",
    "        return int(subprocess.getoutput(r'find ' + path + ' -type f | wc -l'))\n",
    "    \n",
    "    def load_flo(path):\n",
    "        img = np.fromfile(path, np.float32, HEIGHT * WIDTH * 2)\n",
    "        img = img.reshape(HEIGHT, WIDTH, 2)\n",
    "        img[0, 0, :] = img.reshape(HEIGHT * WIDTH, 2)[1:].mean(axis=0)\n",
    "        img -= np.min(img, axis=(0, 1))\n",
    "        img = img / np.max(img, axis=(0, 1))\n",
    "        return img\n",
    "    \n",
    "    extension = 'flo'\n",
    "    load_img_fn = load_flo\n",
    "    n_channels = 2\n",
    "    \n",
    "    train_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test, 'flow')\n",
    "\n",
    "    file_gen = glob.iglob('{}/**/*.{}'.format(train_path, extension), recursive=True)\n",
    "    file_count = get_file_count(train_path)\n",
    "\n",
    "    \n",
    "    for img_path in tqdm_notebook(file_gen, total=file_count):\n",
    "        img = load_flo(img_path)\n",
    "        img.tofile(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33aff828dd2a4dfc82353f28a162a9e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix_flows('train')\n",
    "fix_flows('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img.tofile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stat.txt', 'w+') as f:\n",
    "    f.write(str((rgb_stat, flow_stat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T17:25:01.224762Z",
     "start_time": "2017-09-06T17:25:01.222846Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-07T00:07:09.557887Z",
     "start_time": "2017-09-07T00:07:09.554453Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_count1():\n",
    "    return int(subprocess.getoutput('find /media/d/vsd/data/ucf101_preprocessed/split_01/test/rgb/ -type f | wc -l'))\n",
    "\n",
    "def get_count2():\n",
    "    return int(subprocess.getoutput('find /media/e/vsd/data/ucf101_preprocessed/split_01/train/rgb/ -type f | wc -l'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-07T00:07:21.184665Z",
     "start_time": "2017-09-07T00:07:12.990877Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_count2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c3ed0de1e99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_count2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_count2' is not defined"
     ]
    }
   ],
   "source": [
    "get_count2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18366"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T18:24:29.943232Z",
     "start_time": "2017-09-06T17:25:23.438686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def get_count():\n",
    "    return int(subprocess.getoutput('find /data/data/ucf101_preprocessed/split_01/train/flow/ -type f | wc -l'))\n",
    "\n",
    "while False:\n",
    "    t1 = time.time()\n",
    "    c1 = get_count()\n",
    "    time.sleep(30)\n",
    "    c2 = get_count()\n",
    "    t2 = time.time()\n",
    "    \n",
    "    dc = c2 - c1\n",
    "    dt = t2 - t1\n",
    "    \n",
    "    fps = dc / dt\n",
    "    print(fps, 'f/s')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-07T00:01:51.712029Z",
     "start_time": "2017-09-07T00:01:50.935004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693433"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T15:47:58.672983Z",
     "start_time": "2017-09-06T15:47:58.374686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('find /media/d/vsd/data/ucf101_preprocessed/split_01/test/flow/ -type f | wc -l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T06:53:17.010232Z",
     "start_time": "2017-09-06T06:53:17.006044Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cd PREPROCESSED_SPLIT_PATH\n",
    "# cp run-notwork.sh to PREPROCESSED_SPLIT_PATH\n",
    "# run gen_flow.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## повалидируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: clip flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T08:16:05.934784Z",
     "start_time": "2017-09-06T08:16:05.919245Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_generated_flow(train_or_test):\n",
    "    rgb_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test, 'rgb')\n",
    "    flow_path = os.path.join(PREPROCESSED_SPLIT_PATH, train_or_test, 'flow')\n",
    "    helpers.ensure_path_exists(flow_path)\n",
    "    \n",
    "    path_prefix_len = len(PREPROCESSED_SPLIT_PATH) + 1\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for class_ in tqdm_notebook(os.listdir(rgb_path), desc='[{}] Flow Validation'.format(train_or_test)):\n",
    "        src_class_path = os.path.join(rgb_path, class_)\n",
    "        dst_class_path = os.path.join(flow_path, class_)\n",
    "        helpers.ensure_path_exists(dst_class_path)\n",
    "        \n",
    "        for video_name in os.listdir(src_class_path):\n",
    "            src_video_path = os.path.join(src_class_path, video_name)\n",
    "            dst_video_path = os.path.join(dst_class_path, video_name)\n",
    "            \n",
    "            if len(os.listdir(src_video_path)) - len(os.listdir(dst_video_path)) != 0:\n",
    "                errors.append(video_name)\n",
    "                \n",
    "    return errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
